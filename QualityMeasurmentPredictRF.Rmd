---
title: "HumanActivityRecognition"
author: "Abiyu Giday"
date: "November 22, 2015"
output:
  pdf_document:
    toc: yes
  html_document:
    toc: yes
  word_document: default
---

#Motivation:
<img src="https://pupillageandhowtogetit.files.wordpress.com/2013/04/jsw_measuring_quality_764.jpg" align="right" width="35%" height="35%" />

When it comes to sports exercise, quantifying repetition of a particular activity is easier than measuring quality or how well the an exercise is performed. Paying attention to both frequency and quality will result in optimal results.  However, measuring quality of physical activity is a subtle but important aspect that differs from one person to the other.  Here we will discuss how machine Machine Learning (ML) algorithm is utilized to recognize exercise patterns for six individuals in the experiment and accurately predict which person performed which 1 of 5  quality grade exercises.  On this case, after considering Support Vector Machine (SVM) and Neural Network (NNET) algorithms,  a Random Forest (RF) algorithm resulted in 98% level of accuracy after it was trained with a Human Activity Recognition (HAR) dataset comes from [here.](http://groupware.les.inf.puc-rio.br/har)  Caret package’s ‘Train’ function was used to preprocess, train and tune the model for the human activity recognition dataset.  Principal Component Analysis (PCA) function was used to in the preprocessing stage to separate the signal from the noise and select optimal features based on finding new set of multivariate variables that represent as much of the variability.  PCA needed 25 features to capture 95% of the variance.  Because the dataset contains 19,622 observations and 160 features, a fairly large data size for personal computers, the ‘foreach’ and ‘doMC’ packages were used to configure 8 core processors to cut the amount of time it took to train the RF algorithm from 3+ hours to 10 minutes. 


#The Experiment:
Here is an excerpt from the paper written to describe the experiment:

"_This human activity recognition research has traditionally focused on discriminating between different activities, i.e. to predict "which" activity was performed at a specific point in time (like with the Daily Living Activities dataset above). The approach we propose for the Weight Lifting Exercises dataset is to investigate "how (well)" an activity was performed by the wearer. The "how (well)" investigation has only received little attention so far, even though it potentially provides useful information for a large variety of applications,such as sports training._  

_In this work (see the paper) we first define quality of execution and investigate three aspects that pertain to qualitative activity recognition: the problem of specifying correct execution, the automatic and robust detection of execution mistakes, and how to provide feedback on the quality of execution to the user. We tried out an on-body sensing approach (dataset here), but also an "ambient sensing approach" (by using Microsoft Kinect - dataset still unavailable)_

_Six young health participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions: exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E)._"


#Machine Learning Steps
The following steps detail the data collection and exploration steps, followed by how  parallel computing was configured and used to minimize the amount to time it took to process the data. We then discuss the steps to train, tune  and evaluate the data.

##Data Collection:
Here are all of 160 features in the original data set. There are two downloads. One for the training datd and the other os the test data.
```{r SetEnv, eval=TRUE, echo=TRUE, cache = TRUE}
setwd("~/Documents/Data-Science/DataScienceSpecialization/MachineLearning/Project1")
#rm(list=ls()) 
#load relevant libraryies
library(dplyr)
library(caret)
library(randomForest)
library(rattle)
library(pROC)
library(evtree)
library(foreach)
library(doMC)
registerDoMC(cores = 8)


#Download training data 
if(!file.exists("./data")){dir.create("./data")}
fileUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(fileUrl, destfile = "./data/pml-training.csv", method = "curl")

trainData <- read.csv("./data/pml-training.csv")

#Structure of the dataset
#str(trainData)
names(trainData)

#Download test data 
if(!file.exists("./data")){dir.create("./data")}
fileUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(fileUrl, destfile = "./data/pml-testing.csv", method = "curl")

testData <- read.csv("./data/pml-testing.csv")

```

##Data Exploration:
In the following syrps we will tidy the data with dplyr package. Variables not used as measurment and contain only missing values are removed resulting in just 53 features.
```{r dataexplor,eval=TRUE, echo=TRUE }
#Remove variables that contain only NA
library(dplyr)
df1 <- trainData
df2 <- df1 %>% select(-matches("^kurtosis|^skewness|^max|^min|^amplitude|^var|^stddev|^avg"))

#Remove variables that do not measure performance & reorder data table with classe feature appearing on column 1
df3 <- df2[,-c(1:7)] 
df3 <- df3[, c(53,1:52)]  

# Structur of the new dataset
str(df3)

#Verify if missing values are in the dataset
sum(is.na(df2))
```


##Parallel Computing:
Here we set the number of cores for parallel computing to 8. This is enabled with the 'doMC' packages. Being able to parallely train the data cut the amount of time by about 90%.  
```{r parallel,eval=TRUE, echo=TRUE}
#Register the number of cores to be used.
library(doMC)
registerDoMC(cores = 8)

```

##Spliting the data into training and validation:
The training data is split using the createDataParition function from the caret package. The split was 75/25. 75% is for training the data and the 25% is used to validate the trained model.   
```{r split,eval=TRUE, echo=TRUE }
library(caret)
#Split the training data into training and validation
set.seed(1582)
inTrain <- createDataPartition(y = df3$classe, p = 0.75, list = FALSE)
train22 <- df3[inTrain,]
valdt22 <- df3[-inTrain,]

#check if missing value exist
dim(train22)
sum(is.na(train22))
dim(valdt22)
sum(is.na(valdt22))

#PreProcessing
```

##Tuning and training the Model
Because it takes long time to train the data when  number of folds or number of resampling iteration is set to 10. On this case we left it to a default.  In the training data Random Forest (rf) is used as method, and Principal Component Analysis (PCA) is turned on for preprocessing, centering and scaling of the data is also excplicityly set. The system.time function is also used to time how long it takes to process the data.   
```{r train,eval=TRUE, echo=TRUE, cache = TRUE}

fitControl <- trainControl( 
        method = "repeatedcv",
        #number = 10,
        #repeats = 10,
        allowParallel = TRUE)

set.seed(222)
system.time(modFit1 <- train(classe ~.,
                             data = train22,
                             method = "rf",
                             preProcess=c("pca","center","scale"),
                             trControl=fitControl))

```
###Plots for the model
The following set of plots show Model vs Accuracy, the Accuracy and kappa no0rmal curves. And the 
```{r modelplot,eval=TRUE, echo=FALSE }
plot(modFit1)
resampleHist(modFit1) #
```

###Variable Importance
Of the 53 variables used in the training data, preprocessing with PCA identfied **25 predictors that can explain 95%** of the variance. 

```{r varimp,eval=TRUE, echo=FALSE }
modFit1$preProcess
varImp(modFit1)
```

####Variable importance plot
```{r varplot, eval=TRUE, echo=FALSE, fig.width = 8, fig.height = 4, fig.align='center',fig.cap = "Var Importance Plot" }
plot(varImp(modFit1))
```

####Scatter plot of selected important variables 

The scatter plot uses the top 4 variables and their relations to each person that participated in the experiment. 
```{r matrixplt, fig.margin = TRUE, fig.width = 8, fig.height = 8, fig.align='center',fig.cap = "Scatterplot Matrix with Ellipses"}
# Scatterplot Matrix with Ellipses
featurePlot(x = df2[, c(8,10,20,45)],
            y = df2$user_name,
            plot = "ellipse",
            ## Add a key at the top
            auto.key = list(columns = 3))
```

#Model Evaluation:
To evaluate the models the **confustionMatrix** function on the valdation data is used as shown below. And it shows about 98% accuracy and 0.97% error rate. P value is  2.2e-16 < 0.05 which is acceptable significant. With the 95% confidence interval within the range of (0.9719, 0.9806). Sensetivity and specificity for the model are in the ranges of 94-99% for all 5 qualities (A-E) that are predicted by the moedl. The Kappy value is  97%, combined with all the other indicators, lead to a very high accuracy predition. 
```{r modeval,eval=TRUE, echo=TRUE }
modFit1$finalModel
confusionMatrix(valdt22$classe,predict(modFit1,valdt22))

# area under the ROC curve for each predictor 
RocImportance <- filterVarImp(x=train22[,-ncol(train22)], y = train22$classe)
head(RocImportance)
plot(RocImportance)


#Testing the model against the testData
data.frame(TestData = testData$user_name, Predicted = predict(modFit1, testData))

```

#Take Away:
The objective of this excise had been to create a model that will accurately recognize patterns and predict the manner (quality) in which the participants of the experiment exercised from the collected dataset.  Utilizing the Random Forest algorithm, a model was generated with Caret packages trControl function, and preprocessed with PCA that select optimal number of high valued variables. Although the the accu resulted in 99.25% pattern recognition and prediction accuracy.  


#Reference

_Ugulino, W.; Cardador, D.; Vega, K.; Velloso, E.; Milidiu, R.; Fuks, H. Wearable Computing: Accelerometers' Data Classification of Body Postures and Movements Read more: http://groupware.les.inf.puc-rio.br/har#ixzz3sEPIq2gc_

_Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013. Read more: http://groupware.les.inf.puc-rio.br/har#wle_paper_section#ixzz3sGJpMNZm_

_Max Kuhn. PhD Pfizer Global R&D, http://topepo.github.io/caret/index.html_

_Jeff Leek, PhD - Practical Machine Learning lectures. https://www.coursera.org/course/predmachlearn_  

_Wikepedia: https://en.wikipedia.org/wiki/Machine_learning_

_StackOverflow: http://stackoverflow.com/_

